# -*- coding: utf-8 -*-
"""Module-9:Generative-AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N352cyPCDKUXSNkFN_FOMiqQWERhT95T

# **TASK-1**
"""

from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline

def main1():
    # Load tokenizer and model
    model_name = "Salesforce/codegen-350M-mono"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name, device_map="cpu")

    # Setup pipeline
    codegen = pipeline("text-generation",model=model,tokenizer=tokenizer,max_new_tokens=200,pad_token_id=tokenizer.eos_token_id)

    return codegen

codegen = main1()

# Get user input
prompt = input("Enter your programming question or request: ")

# Generate Python code
result = codegen(prompt, truncation=True)

# Print generated Python code
print("\nGenerated Python Code:\n")
print(result[0]["generated_text"])

"""# **TASK-2**"""

!pip install diffusers --upgrade

!pip install invisible_watermark transformers accelerate safetensors

import torch
from diffusers import DiffusionPipeline

pipe = DiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, use_safetensors=True, variant="fp16")
pipe.to("cuda")

prompt = "A futuristic smart city with flying cars, digital art"

images = pipe(prompt=prompt).images[0]

images.save("ai_image.png")
images.show()

